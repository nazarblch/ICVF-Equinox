{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import jax\n",
    "import os\n",
    "os.environ[\"D4RL_SUPPRESS_IMPORT_ERROR\"] = \"1\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:45:31\n",
      "/home/m_bobrin/anaconda3/envs/icvf/lib/python3.9/site-packages/flax/linen/linear.py:30: DeprecationWarning: jax.ShapedArray is deprecated. Use jax.core.ShapedArray\n",
      "  from jax import ShapedArray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Goal:  (33.24260065681753, 25.045786800033035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|██████████| 8/8 [00:02<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from icvf_envs.antmaze import d4rl_utils, d4rl_ant, d4rl_pm\n",
    "from src.gc_dataset import GCSDataset\n",
    "\n",
    "gcdataset_config = GCSDataset.get_default_config()\n",
    "\n",
    "env = d4rl_utils.make_env(\"antmaze-large-diverse-v2\")\n",
    "dataset = d4rl_utils.get_dataset(env)\n",
    "gc_dataset = GCSDataset(dataset, **gcdataset_config.to_dict())\n",
    "example_batch = gc_dataset.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def segment(observations, terminals, max_path_length):\n",
    "    \"\"\"\n",
    "        segment `observations` into trajectories according to `terminals`\n",
    "    \"\"\"\n",
    "    assert len(observations) == len(terminals)\n",
    "    observation_dim = observations.shape[1]\n",
    "\n",
    "    trajectories = [[]]\n",
    "    for obs, term in zip(observations, terminals):\n",
    "        trajectories[-1].append(obs)\n",
    "        if term.squeeze():\n",
    "            trajectories.append([])\n",
    "\n",
    "    if len(trajectories[-1]) == 0:\n",
    "        trajectories = trajectories[:-1]\n",
    "\n",
    "    ## list of arrays because trajectories lengths will be different\n",
    "    trajectories = [np.stack(traj, axis=0) for traj in trajectories]\n",
    "\n",
    "    n_trajectories = len(trajectories)\n",
    "    path_lengths = [len(traj) for traj in trajectories]\n",
    "\n",
    "    ## pad trajectories to be of equal length\n",
    "    trajectories_pad = np.zeros((n_trajectories, max_path_length, observation_dim), dtype=trajectories[0].dtype)\n",
    "    early_termination = np.zeros((n_trajectories, max_path_length), dtype=np.bool)\n",
    "    for i, traj in enumerate(trajectories):\n",
    "        path_length = path_lengths[i]\n",
    "        trajectories_pad[i,:path_length] = traj\n",
    "        early_termination[i,path_length:] = 1\n",
    "\n",
    "    return trajectories_pad, early_termination, path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9296/2316572737.py:27: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  early_termination = np.zeros((n_trajectories, max_path_length), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "test_obs = jnp.concatenate([dataset['observations'], dataset['next_observations']], axis=1)\n",
    "segmented = segment(test_obs, dataset['dones_float'], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "terminal_indxes = np.argwhere(dataset[\"dones_float\"] > 0.5).squeeze()\n",
    "random_idx = np.random.choice(terminal_indxes, size=2, replace=False)\n",
    "len(random_idx)\n",
    "#dataset.get_subset(random_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['actions', 'dones_float', 'masks', 'next_observations', 'observations', 'rewards', 'desired_rewards', 'desired_masks', 'goals', 'desired_goals'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each token - (observations, next_observations, dones_float)\n",
    "For ant_maze obs space is vector of size 29, action - 8. Dones - as positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 29)\n",
      "(10, 29)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(gc_dataset.sample_trajectories(2)[1]['observations'].shape)\n",
    "print(gc_dataset.sample_trajectories(2)[1]['next_observations'].shape)\n",
    "print(gc_dataset.sample_trajectories(2)[1]['dones_float'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc_dataset.sample_trajectories(2)[0]['observations'][::5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "import flax.linen as nn\n",
    "import einops\n",
    "import jax.numpy as jnp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class VqvaeConfig:\n",
    "    embedding_dim: int = 128\n",
    "    num_tokens: int = 2 # each pair = one token\n",
    "    trajectory_len: int = 10\n",
    "    \n",
    "    run_opt: str = field(default='train')\n",
    "    adam_beta1: float = .9\n",
    "    adam_beta2: float = .9\n",
    "    lr: float = 3e-5\n",
    "    ema_rate: float = 0.\n",
    "    n_batch: int = 32   \n",
    "    warmup_iters: float = 100.\n",
    "    wd: float = 0.\n",
    "    grad_clip: float = 200.     \n",
    "    dtype: str = \"float32\"\n",
    "    checkpoint: bool = False\n",
    "    \n",
    "    iters_per_ckpt: int = 25000\n",
    "    iters_per_images: int = 10000\n",
    "    iters_per_print: int = 1000\n",
    "    iters_per_save: int = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "from flax import linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# inspired from Haiku's corresponding code\n",
    "# https://github.com/deepmind/dm-haiku/blob/master/haiku/_src/moving_averages.py\n",
    "\n",
    "class ExponentialMovingAverage(nn.Module):\n",
    "  shape: list\n",
    "  dtype: Any = jnp.float32\n",
    "  decay: float = 0.\n",
    "\n",
    "  def setup(self):\n",
    "    shape = self.shape\n",
    "    dtype = self.dtype\n",
    "    self.hidden = self.variable(\"stats\", \"hidden\", lambda: jnp.zeros(shape, dtype=dtype))\n",
    "    self.average = self.variable(\"stats\", \"average\", lambda: jnp.zeros(shape, dtype=dtype)) # how to deal with initialized?\n",
    "    constant = lambda: jnp.zeros(shape, dtype=jnp.int32)\n",
    "    self.counter = self.variable(\"stats\", \"counter\", constant)\n",
    "\n",
    "  def __call__(\n",
    "      self,\n",
    "      value: jnp.ndarray,\n",
    "      update_stats: bool = True,\n",
    "  ) -> jnp.ndarray:\n",
    "\n",
    "    counter = self.counter.value + 1\n",
    "    decay = jax.lax.convert_element_type(self.decay, value.dtype)\n",
    "    one = jnp.ones([], value.dtype)\n",
    "    hidden = self.hidden.value * decay + value * (one - decay)\n",
    "\n",
    "    average = hidden\n",
    "    average /= (one - jnp.power(decay, counter))\n",
    "    if update_stats:\n",
    "      self.counter.value = counter\n",
    "      self.hidden.value = hidden\n",
    "      self.average.value = average\n",
    "    return average\n",
    "\n",
    "# inspired from Haiku's corresponding code to Flax\n",
    "# https://github.com/deepmind/dm-haiku/blob/master/haiku/_src/nets/vqvae.py\n",
    "\n",
    "class VectorQuantizerEMA(nn.Module):\n",
    "  embedding_dim: int\n",
    "  num_embeddings: int\n",
    "  commitment_cost: float\n",
    "  decay: float\n",
    "  epsilon: float = 1e-5\n",
    "  dtype: Any = jnp.float32\n",
    "  cross_replica_axis: Optional[str] = None  \n",
    "  initialized: bool = False\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs, is_training, rng=None, encoding_indices=None):\n",
    "    embedding_shape = [self.embedding_dim, self.num_embeddings]\n",
    "    assert self.dtype == jnp.float32\n",
    "    ema_cluster_size = ExponentialMovingAverage([self.num_embeddings], self.dtype, decay=self.decay)\n",
    "    ema_dw = ExponentialMovingAverage(embedding_shape, self.dtype, decay=self.decay)\n",
    "    initialized = self.has_variable('stats', 'embeddings')\n",
    "    embeddings = self.variable(\"stats\", \"embeddings\", nn.initializers.lecun_uniform(), rng, embedding_shape)\n",
    "    \n",
    "    def quantize(encoding_indices):\n",
    "        \"\"\"Returns embedding tensor for a batch of indices.\"\"\"\n",
    "        w = embeddings.value.swapaxes(1, 0)\n",
    "        w = jax.device_put(w)  # Required when embeddings is a NumPy array.\n",
    "        return w[(encoding_indices,)]\n",
    "\n",
    "    if encoding_indices is not None:\n",
    "        return quantize(encoding_indices)\n",
    "    \n",
    "    if not initialized:\n",
    "        hidden, counter, average = ema_cluster_size.hidden, ema_cluster_size.counter, ema_cluster_size.average\n",
    "        hidden, counter, average = ema_dw.hidden, ema_dw.counter, ema_dw.average     \n",
    "        return {\n",
    "            \"quantize\": inputs,\n",
    "            \"loss\": inputs.mean(),\n",
    "        }\n",
    "    \n",
    "    flat_inputs = jnp.reshape(inputs, [-1, self.embedding_dim])\n",
    "    distances = (\n",
    "        jnp.sum(flat_inputs**2, 1, keepdims=True) -\n",
    "        2 * jnp.matmul(flat_inputs, embeddings.value) +\n",
    "        jnp.sum(embeddings.value**2, 0, keepdims=True))\n",
    "\n",
    "    encoding_indices = jnp.argmax(-distances, 1)\n",
    "    encodings = jax.nn.one_hot(encoding_indices,\n",
    "                               self.num_embeddings,\n",
    "                               dtype=distances.dtype)\n",
    "\n",
    "    encoding_indices = jnp.reshape(encoding_indices, inputs.shape[:-1])\n",
    "    quantized = quantize(encoding_indices)\n",
    "    e_latent_loss = jnp.mean((jax.lax.stop_gradient(quantized) - inputs)**2)\n",
    "\n",
    "    if is_training:\n",
    "      cluster_size = jnp.sum(encodings, axis=0)\n",
    "      if self.cross_replica_axis:\n",
    "        cluster_size = jax.lax.psum(\n",
    "            cluster_size, axis_name=self.cross_replica_axis)\n",
    "      updated_ema_cluster_size = ema_cluster_size(cluster_size, update_stats=is_training)\n",
    "\n",
    "      dw = jnp.matmul(flat_inputs.T, encodings)\n",
    "      if self.cross_replica_axis:\n",
    "        dw = jax.lax.psum(dw, axis_name=self.cross_replica_axis)\n",
    "      updated_ema_dw = ema_dw(dw, update_stats=is_training)\n",
    "\n",
    "      n = jnp.sum(updated_ema_cluster_size)\n",
    "      updated_ema_cluster_size = ((updated_ema_cluster_size + self.epsilon) /\n",
    "                                  (n + self.num_embeddings * self.epsilon) * n)\n",
    "\n",
    "      normalised_updated_ema_w = (\n",
    "          updated_ema_dw / jnp.reshape(updated_ema_cluster_size, [1, -1]))\n",
    "\n",
    "      embeddings.value = normalised_updated_ema_w\n",
    "      loss = self.commitment_cost * e_latent_loss\n",
    "\n",
    "    else:\n",
    "      loss = self.commitment_cost * e_latent_loss\n",
    "\n",
    "    # Straight Through Estimator\n",
    "    quantized = inputs + jax.lax.stop_gradient(quantized - inputs)\n",
    "    avg_probs = jnp.mean(encodings, 0)\n",
    "    if self.cross_replica_axis:\n",
    "      avg_probs = jax.lax.pmean(avg_probs, axis_name=self.cross_replica_axis)\n",
    "    perplexity = jnp.exp(-jnp.sum(avg_probs * jnp.log(avg_probs + 1e-10)))\n",
    "\n",
    "    return {\n",
    "        \"quantize\": quantized,\n",
    "        \"loss\": loss,\n",
    "        \"perplexity\": perplexity,\n",
    "        \"encodings\": encodings,\n",
    "        \"encoding_indices\": encoding_indices,\n",
    "        \"distances\": distances,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import jax.numpy as jnp\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    hyperparams: VqvaeConfig\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, traj_info) -> Any:\n",
    "        \n",
    "        obs = traj_info['observations']\n",
    "        next_obs = traj_info['next_observations']\n",
    "        dones = traj_info['dones_float']\n",
    "        \n",
    "        obs_emb = nn.Dense(features=self.hyperparams.embedding_dim)(obs)\n",
    "        next_obs_emb = nn.Dense(features=self.hyperparams.embedding_dim)(next_obs)\n",
    "        token_emb = jnp.reshape(jnp.concatenate([obs_emb, next_obs_emb], axis=1), (5*2, self.hyperparams.embedding_dim*2))\n",
    "        \n",
    "        goal_token = self.param('cls', nn.initializers.zeros, [1, self.hyperparams.embedding_dim*2])\n",
    "        #goal_token = jnp.repeat(goal_token, repeats=token_emb.shape[0], axis=0)\n",
    "        pos_embedding = self.param('pos_embedding', nn.initializers.zeros, [self.hyperparams.trajectory_len+1, self.hyperparams.embedding_dim*2])\n",
    "        token_emb = jnp.concatenate([token_emb, goal_token], axis=0)\n",
    "        token_emb += pos_embedding[:2*self.hyperparams.trajectory_len + 1]\n",
    "        \n",
    "        return token_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "key1, keys = jax.random.split(key, 2)\n",
    "\n",
    "# Tokens x observ_dim\n",
    "example = gc_dataset.sample_trajectories(2)[1]\n",
    "model = VQVAE(VqvaeConfig)\n",
    "init_vars = model.init(key1, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 256)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_vars, example).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vq = VectorQuantizerEMA()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icvf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
